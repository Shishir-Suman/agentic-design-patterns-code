{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b4848df-095b-4ddd-81ac-5949ab25c30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- Configuration ---\n",
    "# Load environment variables from .env file (for OPENAI_API_KEY)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd624f3b-4e5d-4a76-896e-1d9076c64727",
   "metadata": {},
   "source": [
    "# 1. LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e97b37-9cdd-4ec4-aceb-36d5869a8820",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b862b9e3-61a8-4654-9ffd-4128fce28f4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from typing import List\n",
    "\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "# Ensure your GOOGLE_API_KEY environment variable is set.\n",
    "try:\n",
    "   # A model with function/tool calling capabilities is required.\n",
    "   llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0)\n",
    "   print(f\"✅ Language model initialized: {llm.model}\")\n",
    "except Exception as e:\n",
    "   print(f\"🛑 Error initializing language model: {e}\")\n",
    "   llm = None\n",
    "\n",
    "# --- Define a Tool ---\n",
    "@tool\n",
    "def search_information(query: str) -> str:\n",
    "   \"\"\"\n",
    "   Provides factual information on a given topic. Use this tool to find answers to phrases\n",
    "   like 'capital of France' or 'weather in London?'.\n",
    "   \"\"\"\n",
    "   print(f\"\\n--- 🛠️ Tool Called: search_information with query: '{query}' ---\")\n",
    "   # Simulate a search tool with a dictionary of predefined results.\n",
    "   simulated_results = {\n",
    "       \"weather in london\": \"The weather in London is currently cloudy with a temperature of 15°C.\",\n",
    "       \"capital of france\": \"The capital of France is Paris.\",\n",
    "       \"population of earth\": \"The estimated population of Earth is around 8 billion people.\",\n",
    "       \"tallest mountain\": \"Mount Everest is the tallest mountain above sea level.\",\n",
    "       \"default\": f\"Simulated search result for '{query}': No specific information found, but the topic seems interesting.\"\n",
    "   }\n",
    "   result = simulated_results.get(query.lower(), simulated_results[\"default\"])\n",
    "   print(f\"--- TOOL RESULT: {result} ---\")\n",
    "   return result\n",
    "\n",
    "\n",
    "tools = [search_information]\n",
    "\n",
    "\n",
    "# --- Create a Tool-Calling Agent ---\n",
    "if llm:\n",
    "   # This prompt template requires an `agent_scratchpad` placeholder for the agent's internal steps.\n",
    "   agent_prompt = ChatPromptTemplate.from_messages([\n",
    "       (\"system\", \"You are a helpful assistant.\"),\n",
    "       (\"human\", \"{input}\"),\n",
    "       (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "   ])\n",
    "\n",
    "\n",
    "   # Create the agent, binding the LLM, tools, and prompt together.\n",
    "   agent = create_tool_calling_agent(llm, tools, agent_prompt)\n",
    "\n",
    "\n",
    "   # AgentExecutor is the runtime that invokes the agent and executes the chosen tools.\n",
    "   # The 'tools' argument is not needed here as they are already bound to the agent.\n",
    "   agent_executor = AgentExecutor(agent=agent, verbose=True, tools=tools)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "async def run_agent_with_tool(query: str):\n",
    "   \"\"\"Invokes the agent executor with a query and prints the final response.\"\"\"\n",
    "   print(f\"\\n--- 🏃 Running Agent with Query: '{query}' ---\")\n",
    "   try:\n",
    "       response = await agent_executor.ainvoke({\"input\": query})\n",
    "       print(\"\\n--- ✅ Final Agent Response ---\")\n",
    "       print(response[\"output\"])\n",
    "   except Exception as e:\n",
    "       print(f\"\\n🛑 An error occurred during agent execution: {e}\")\n",
    "\n",
    "\n",
    "async def main():\n",
    "   \"\"\"Runs all agent queries concurrently.\"\"\"\n",
    "   tasks = [\n",
    "       run_agent_with_tool(\"What is the capital of France?\"),\n",
    "       run_agent_with_tool(\"What's the weather like in London?\"),\n",
    "       run_agent_with_tool(\"Tell me something about dogs.\") # Should trigger the default tool response\n",
    "   ]\n",
    "   await asyncio.gather(*tasks)\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa008f4-94a2-4a8b-8165-f6fd213c0d40",
   "metadata": {},
   "source": [
    "# 2. Crew AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31df7900-9b2b-456c-b018-6a32db662bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install crewai langchain-openai\n",
    "\n",
    "\n",
    "import os\n",
    "from crewai import Agent, Task, Crew\n",
    "from crewai.tools import tool\n",
    "import logging\n",
    "\n",
    "\n",
    "# --- Best Practice: Configure Logging ---\n",
    "# A basic logging setup helps in debugging and tracking the crew's execution.\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "# --- Set up your API Key ---\n",
    "# For production, it's recommended to use a more secure method for key management\n",
    "# like environment variables loaded at runtime or a secret manager.\n",
    "#\n",
    "# Set the environment variable for your chosen LLM provider (e.g., OPENAI_API_KEY)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\n",
    "# os.environ[\"OPENAI_MODEL_NAME\"] = \"gpt-4o\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- 1. Refactored Tool: Returns Clean Data ---\n",
    "# The tool now returns raw data (a float) or raises a standard Python error.\n",
    "# This makes it more reusable and forces the agent to handle outcomes properly.\n",
    "@tool(\"Stock Price Lookup Tool\")\n",
    "def get_stock_price(ticker: str) -> float:\n",
    "   \"\"\"\n",
    "   Fetches the latest simulated stock price for a given stock ticker symbol.\n",
    "   Returns the price as a float. Raises a ValueError if the ticker is not found.\n",
    "   \"\"\"\n",
    "   logging.info(f\"Tool Call: get_stock_price for ticker '{ticker}'\")\n",
    "   simulated_prices = {\n",
    "       \"AAPL\": 178.15,\n",
    "       \"GOOGL\": 1750.30,\n",
    "       \"MSFT\": 425.50,\n",
    "   }\n",
    "   price = simulated_prices.get(ticker.upper())\n",
    "\n",
    "\n",
    "   if price is not None:\n",
    "       return price\n",
    "   else:\n",
    "       # Raising a specific error is better than returning a string.\n",
    "       # The agent is equipped to handle exceptions and can decide on the next action.\n",
    "       raise ValueError(f\"Simulated price for ticker '{ticker.upper()}' not found.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- 2. Define the Agent ---\n",
    "# The agent definition remains the same, but it will now leverage the improved tool.\n",
    "financial_analyst_agent = Agent(\n",
    " role='Senior Financial Analyst',\n",
    " goal='Analyze stock data using provided tools and report key prices.',\n",
    " backstory=\"You are an experienced financial analyst adept at using data sources to find stock information. You provide clear, direct answers.\",\n",
    " verbose=True,\n",
    " tools=[get_stock_price],\n",
    " # Allowing delegation can be useful, but is not necessary for this simple task.\n",
    " allow_delegation=False,\n",
    ")\n",
    "\n",
    "\n",
    "# --- 3. Refined Task: Clearer Instructions and Error Handling ---\n",
    "# The task description is more specific and guides the agent on how to react\n",
    "# to both successful data retrieval and potential errors.\n",
    "analyze_aapl_task = Task(\n",
    " description=(\n",
    "     \"What is the current simulated stock price for Apple (ticker: AAPL)? \"\n",
    "     \"Use the 'Stock Price Lookup Tool' to find it. \"\n",
    "     \"If the ticker is not found, you must report that you were unable to retrieve the price.\"\n",
    " ),\n",
    " expected_output=(\n",
    "     \"A single, clear sentence stating the simulated stock price for AAPL. \"\n",
    "     \"For example: 'The simulated stock price for AAPL is $178.15.' \"\n",
    "     \"If the price cannot be found, state that clearly.\"\n",
    " ),\n",
    " agent=financial_analyst_agent,\n",
    ")\n",
    "\n",
    "\n",
    "# --- 4. Formulate the Crew ---\n",
    "# The crew orchestrates how the agent and task work together.\n",
    "financial_crew = Crew(\n",
    " agents=[financial_analyst_agent],\n",
    " tasks=[analyze_aapl_task],\n",
    " verbose=True # Set to False for less detailed logs in production\n",
    ")\n",
    "\n",
    "\n",
    "# --- 5. Run the Crew within a Main Execution Block ---\n",
    "# Using a __name__ == \"__main__\": block is a standard Python best practice.\n",
    "def main():\n",
    "   \"\"\"Main function to run the crew.\"\"\"\n",
    "   # Check for API key before starting to avoid runtime errors.\n",
    "   if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "       print(\"ERROR: The OPENAI_API_KEY environment variable is not set.\")\n",
    "       print(\"Please set it before running the script.\")\n",
    "       return\n",
    "\n",
    "\n",
    "   print(\"\\n## Starting the Financial Crew...\")\n",
    "   print(\"---------------------------------\")\n",
    "  \n",
    "   # The kickoff method starts the execution.\n",
    "   result = financial_crew.kickoff()\n",
    "\n",
    "\n",
    "   print(\"\\n---------------------------------\")\n",
    "   print(\"## Crew execution finished.\")\n",
    "   print(\"\\nFinal Result:\\n\", result)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01de8db8-25f9-420f-9698-8e93c8ab98fe",
   "metadata": {},
   "source": [
    "# 2. Google ADK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04c9ab5-bbfe-4eb3-aa2d-64f8bfcd97b3",
   "metadata": {},
   "source": [
    "## 2.1 Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350b5cb0-666f-46a6-b0b3-4d3c5df6c760",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from google.adk.agents import Agent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.tools import google_search\n",
    "from google.genai import types\n",
    "import nest_asyncio\n",
    "\n",
    "APP_NAME=\"Google Search_agent\"\n",
    "USER_ID=\"user1234\"\n",
    "SESSION_ID=\"1234\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "root_agent = Agent(\n",
    "   name=\"basic_search_agent\",\n",
    "   model=\"gemini-2.0-flash-exp\",\n",
    "   description=\"Agent to answer questions using Google Search.\",\n",
    "   instruction=\"I can answer your questions by searching the internet. Just ask me anything!\",\n",
    "   # Google Search is a pre-built tool which allows the agent to perform Google searches.\n",
    "   tools=[google_search]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Agent Interaction\n",
    "async def call_agent(query):\n",
    "   \"\"\"\n",
    "   Helper function to call the agent with a query.\n",
    "   \"\"\"\n",
    "    \n",
    "   # Session and Runner\n",
    "   session_service = InMemorySessionService()\n",
    "   session = await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID)\n",
    "   runner = Runner(agent=root_agent, app_name=APP_NAME, session_service=session_service)\n",
    "\n",
    "   content = types.Content(role='user', parts=[types.Part(text=query)])\n",
    "   events = runner.run(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n",
    "\n",
    "\n",
    "   for event in events:\n",
    "       if event.is_final_response():\n",
    "           final_response = event.content.parts[0].text\n",
    "           print(\"Agent Response: \", final_response)\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "await call_agent(\"what's the latest ai news?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dde5f6e-4d28-4015-842d-5b53beb5b638",
   "metadata": {},
   "source": [
    "## 2.2 Code Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0e485c0-98a8-49a8-a373-7832c500b955",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Query: Calculate the value of (5 + 7) * 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['executable_code', 'code_execution_result'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID: 91226734-602b-464e-bc3d-4612f4af1139, Author: calculator_agent\n",
      "  Debug: Agent generated code:\n",
      "```python\n",
      "print((5 + 7) * 3)\n",
      "\n",
      "```\n",
      "  Debug: Code Execution Result: Outcome.OUTCOME_OK - Output:\n",
      "36\n",
      "\n",
      "  Text: '36'\n",
      "==> Final Agent Response: 36\n",
      "\n",
      "------------------------------\n",
      "\n",
      "--- Running Query: What is 10 factorial? ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['executable_code', 'code_execution_result'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID: 0e82a9fa-d33e-410d-b6cc-805bd56e505d, Author: calculator_agent\n",
      "  Debug: Agent generated code:\n",
      "```python\n",
      "import math\n",
      "print(math.factorial(10))\n",
      "\n",
      "```\n",
      "  Debug: Code Execution Result: Outcome.OUTCOME_OK - Output:\n",
      "3628800\n",
      "\n",
      "  Text: '3628800'\n",
      "==> Final Agent Response: 3628800\n",
      "\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.genai import types\n",
    "from google.adk.code_executors import BuiltInCodeExecutor\n",
    "import nest_asyncio\n",
    "\n",
    "AGENT_NAME=\"calculator_agent\"\n",
    "APP_NAME=\"calculator\"\n",
    "USER_ID=\"user1234\"\n",
    "SESSION_ID=\"session_code_exec_async\"\n",
    "GEMINI_MODEL = \"gemini-2.0-flash\"\n",
    "\n",
    "\n",
    "# Agent Definition\n",
    "code_agent = LlmAgent(\n",
    "   name=AGENT_NAME,\n",
    "   model=GEMINI_MODEL,\n",
    "   code_executor=BuiltInCodeExecutor(),\n",
    "   instruction=\"\"\"You are a calculator agent.\n",
    "   When given a mathematical expression, write and execute Python code to calculate the result.\n",
    "   Return only the final numerical result as plain text, without markdown or code blocks.\n",
    "   \"\"\",\n",
    "   description=\"Executes Python code to perform calculations.\",\n",
    ")\n",
    "\n",
    "# Agent Interaction (Async)\n",
    "async def call_agent_async(query):\n",
    "\n",
    "   # Session and Runner\n",
    "   session_service = InMemorySessionService()\n",
    "   session = await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID)\n",
    "   runner = Runner(agent=code_agent, app_name=APP_NAME, session_service=session_service)\n",
    "\n",
    "   content = types.Content(role='user', parts=[types.Part(text=query)])\n",
    "   print(f\"\\n--- Running Query: {query} ---\")\n",
    "   final_response_text = \"No final text response captured.\"\n",
    "   try:\n",
    "       # Use run_async\n",
    "       async for event in runner.run_async(user_id=USER_ID, session_id=SESSION_ID, new_message=content):\n",
    "           print(f\"Event ID: {event.id}, Author: {event.author}\")\n",
    "\n",
    "           # --- Check for specific parts FIRST ---\n",
    "           # has_specific_part = False\n",
    "           if event.content and event.content.parts and event.is_final_response():\n",
    "               for part in event.content.parts: # Iterate through all parts\n",
    "                   if part.executable_code:\n",
    "                       # Access the actual code string via .code\n",
    "                       print(f\"  Debug: Agent generated code:\\n```python\\n{part.executable_code.code}\\n```\")\n",
    "                       has_specific_part = True\n",
    "                   elif part.code_execution_result:\n",
    "                       # Access outcome and output correctly\n",
    "                       print(f\"  Debug: Code Execution Result: {part.code_execution_result.outcome} - Output:\\n{part.code_execution_result.output}\")\n",
    "                       has_specific_part = True\n",
    "                   # Also print any text parts found in any event for debugging\n",
    "                   elif part.text and not part.text.isspace():\n",
    "                       print(f\"  Text: '{part.text.strip()}'\")\n",
    "                       # Do not set has_specific_part=True here, as we want the final response logic below\n",
    "               \n",
    "               # --- Check for final response AFTER specific parts ---\n",
    "               text_parts = [part.text for part in event.content.parts if part.text]\n",
    "               final_result = \"\".join(text_parts)\n",
    "               print(f\"==> Final Agent Response: {final_result}\")\n",
    "\n",
    "   except Exception as e:\n",
    "       print(f\"ERROR during agent run: {e}\")\n",
    "   print(\"-\" * 30)\n",
    "\n",
    "# Main async function to run the examples\n",
    "async def main():\n",
    "   await call_agent_async(\"Calculate the value of (5 + 7) * 3\")\n",
    "   await call_agent_async(\"What is 10 factorial?\")\n",
    "\n",
    "\n",
    "# Execute the main async function\n",
    "try:\n",
    "   nest_asyncio.apply()\n",
    "   await main()\n",
    "except RuntimeError as e:\n",
    "   # Handle specific error when running asyncio.run in an already running loop (like Jupyter/Colab)\n",
    "   if \"cannot be called from a running event loop\" in str(e):\n",
    "       print(\"\\nRunning in an existing event loop (like Colab/Jupyter).\")\n",
    "       print(\"Please run `await main()` in a notebook cell instead.\")\n",
    "       # If in an interactive environment like a notebook, you might need to run:\n",
    "       # await main()\n",
    "   else:\n",
    "       raise e # Re-raise other runtime errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63daad22-6512-4e38-9a3d-798fbeb2cf68",
   "metadata": {},
   "source": [
    "## 2.3 Vertex AI Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fffceb-1025-448c-a255-01b1bfbc06bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from google.genai import types\n",
    "from google.adk import agents\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "import os\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "# Ensure you have set your GOOGLE_API_KEY and DATASTORE_ID environment variables\n",
    "# For example:\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_API_KEY\"\n",
    "# os.environ[\"DATASTORE_ID\"] = \"YOUR_DATASTORE_ID\"\n",
    "\n",
    "\n",
    "DATASTORE_ID = os.environ.get(\"DATASTORE_ID\")\n",
    "\n",
    "\n",
    "# --- Application Constants ---\n",
    "APP_NAME = \"vsearch_app\"\n",
    "USER_ID = \"user_123\"  # Example User ID\n",
    "SESSION_ID = \"session_456\" # Example Session ID\n",
    "\n",
    "\n",
    "# --- Agent Definition (Updated with the newer model from the guide) ---\n",
    "vsearch_agent = agents.VSearchAgent(\n",
    "   name=\"q2_strategy_vsearch_agent\",\n",
    "   description=\"Answers questions about Q2 strategy documents using Vertex AI Search.\",\n",
    "   model=\"gemini-2.0-flash-exp\", # Updated model based on the guide's examples\n",
    "   datastore_id=DATASTORE_ID,\n",
    "   model_parameters={\"temperature\": 0.0}\n",
    ")\n",
    "\n",
    "\n",
    "# --- Runner and Session Initialization ---\n",
    "runner = Runner(\n",
    "   agent=vsearch_agent,\n",
    "   app_name=APP_NAME,\n",
    "   session_service=InMemorySessionService(),\n",
    ")\n",
    "\n",
    "\n",
    "# --- Agent Invocation Logic ---\n",
    "async def call_vsearch_agent_async(query: str):\n",
    "   \"\"\"Initializes a session and streams the agent's response.\"\"\"\n",
    "   print(f\"User: {query}\")\n",
    "   print(\"Agent: \", end=\"\", flush=True)\n",
    "\n",
    "\n",
    "   try:\n",
    "       # Construct the message content correctly\n",
    "       content = types.Content(role='user', parts=[types.Part(text=query)])\n",
    "\n",
    "\n",
    "       # Process events as they arrive from the asynchronous runner\n",
    "       async for event in runner.run_async(\n",
    "           user_id=USER_ID,\n",
    "           session_id=SESSION_ID,\n",
    "           new_message=content\n",
    "       ):\n",
    "           # For token-by-token streaming of the response text\n",
    "           if hasattr(event, 'content_part_delta') and event.content_part_delta:\n",
    "               print(event.content_part_delta.text, end=\"\", flush=True)\n",
    "\n",
    "\n",
    "           # Process the final response and its associated metadata\n",
    "           if event.is_final_response():\n",
    "               print() # Newline after the streaming response\n",
    "               if event.grounding_metadata:\n",
    "                   print(f\"  (Source Attributions: {len(event.grounding_metadata.grounding_attributions)} sources found)\")\n",
    "               else:\n",
    "                   print(\"  (No grounding metadata found)\")\n",
    "               print(\"-\" * 30)\n",
    "\n",
    "\n",
    "   except Exception as e:\n",
    "       print(f\"\\nAn error occurred: {e}\")\n",
    "       print(\"Please ensure your datastore ID is correct and that the service account has the necessary permissions.\")\n",
    "       print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- Run Example ---\n",
    "async def run_vsearch_example():\n",
    "   # Replace with a question relevant to YOUR datastore content\n",
    "   await call_vsearch_agent_async(\"Summarize the main points about the Q2 strategy document.\")\n",
    "   await call_vsearch_agent_async(\"What safety procedures are mentioned for lab X?\")\n",
    "\n",
    "\n",
    "# --- Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "   if not DATASTORE_ID:\n",
    "       print(\"Error: DATASTORE_ID environment variable is not set.\")\n",
    "   else:\n",
    "       try:\n",
    "           asyncio.run(run_vsearch_example())\n",
    "       except RuntimeError as e:\n",
    "           # This handles cases where asyncio.run is called in an environment\n",
    "           # that already has a running event loop (like a Jupyter notebook).\n",
    "           if \"cannot be called from a running event loop\" in str(e):\n",
    "               print(\"Skipping execution in a running event loop. Please run this script directly.\")\n",
    "           else:\n",
    "               raise e\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
